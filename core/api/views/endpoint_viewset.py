import json
import logging
import re
import subprocess

import requests
import validators
from bs4 import BeautifulSoup
from django.core import serializers
from django.db.models import CharField, Count, Q, Value
from django.shortcuts import get_object_or_404
from django.utils import timezone
from lxml import html
from packaging import version
from rest_framework import generics, status, viewsets
from rest_framework.decorators import action, api_view
from rest_framework.response import Response
from rest_framework.views import APIView
from selenium import webdriver
from selenium.webdriver.common.by import By
# selenium
from selenium.webdriver.firefox.options import Options as FirefoxOptions
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait

from core.api.serializers.endpoint_only_url_serializer import \
    EndpointOnlyURLsSerializer
from core.api.serializers.endpoint_serializer import EndpointSerializer
from core.celery import app
from core.common_func import *
from core.dashboard.models import *
from core.recon_note.models import *
from core.scanEngine.models import *
from core.startScan.models import *
from core.targetApp.models import *
from core.tasks import (create_scan_activity, initiate_subtask,
                        run_system_commands)
from core.utilities import is_safe_path


class EndPointViewSet(viewsets.ModelViewSet):
    queryset = EndPoint.objects.none()
    serializer_class = EndpointSerializer

    def get_queryset(self):
        req = self.request

        scan_id = req.query_params.get("scan_history")
        target_id = req.query_params.get("target_id")
        url_query = req.query_params.get("query_param")
        subdomain_id = req.query_params.get("subdomain_id")

        gf_tag = (
            req.query_params.get("gf_tag") if "gf_tag" in req.query_params else None
        )

        if scan_id:
            endpoints_queryset = EndPoint.objects.filter(
                scan_history__id=scan_id
            ).distinct()
        elif target_id:
            endpoints_queryset = EndPoint.objects.filter(
                target_domain__id=target_id
            ).distinct()
        else:
            endpoints_queryset = EndPoint.objects.distinct()

        if url_query:
            endpoints_queryset = endpoints_queryset.filter(
                Q(target_domain__name=url_query)
            ).distinct()

        if gf_tag:
            endpoints_queryset = endpoints_queryset.filter(
                matched_gf_patterns__icontains=gf_tag
            )

        if subdomain_id:
            endpoints_queryset = endpoints_queryset.filter(subdomain__id=subdomain_id)

        if "only_urls" in req.query_params:
            self.serializer_class = EndpointOnlyURLsSerializer

        self.queryset = endpoints_queryset

        return self.queryset

    def filter_queryset(self, qs):
        qs = self.queryset.filter()
        search_value = self.request.GET.get("search[value]", None)
        _order_col = self.request.GET.get("order[0][column]", None)
        _order_direction = self.request.GET.get("order[0][dir]", None)
        if search_value or _order_col or _order_direction:
            order_col = "content_length"
            if _order_col == "1":
                order_col = "http_url"
            elif _order_col == "2":
                order_col = "http_status"
            elif _order_col == "3":
                order_col = "page_title"
            elif _order_col == "4":
                order_col = "matched_gf_patterns"
            elif _order_col == "5":
                order_col = "content_type"
            elif _order_col == "6":
                order_col = "content_length"
            elif _order_col == "7":
                order_col = "technologies"
            elif _order_col == "8":
                order_col = "webserver"
            elif _order_col == "9":
                order_col = "response_time"
            if _order_direction == "desc":
                order_col = "-{}".format(order_col)
            # if the search query is separated by = means, it is a specific lookup
            # divide the search query into two half and lookup
            if (
                "=" in search_value
                or "&" in search_value
                or "|" in search_value
                or ">" in search_value
                or "<" in search_value
                or "!" in search_value
            ):
                if "&" in search_value:
                    complex_query = search_value.split("&")
                    for query in complex_query:
                        if query.strip():
                            qs = qs & self.special_lookup(query.strip())
                elif "|" in search_value:
                    qs = Subdomain.objects.none()
                    complex_query = search_value.split("|")
                    for query in complex_query:
                        if query.strip():
                            qs = self.special_lookup(query.strip()) | qs
                else:
                    qs = self.special_lookup(search_value)
            else:
                qs = self.general_lookup(search_value)
            return qs.order_by(order_col)
        return qs

    def general_lookup(self, search_value):
        qs = self.queryset.filter(
            Q(http_url__icontains=search_value)
            | Q(page_title__icontains=search_value)
            | Q(http_status__icontains=search_value)
            | Q(content_type__icontains=search_value)
            | Q(webserver__icontains=search_value)
            | Q(technologies__name__icontains=search_value)
            | Q(content_type__icontains=search_value)
            | Q(matched_gf_patterns__icontains=search_value)
        )

        return qs

    def special_lookup(self, search_value):
        qs = self.queryset.filter()
        if "=" in search_value:
            search_param = search_value.split("=")
            lookup_title = search_param[0].lower().strip()
            lookup_content = search_param[1].lower().strip()
            if "http_url" in lookup_title:
                qs = self.queryset.filter(http_url__icontains=lookup_content)
            elif "page_title" in lookup_title:
                qs = self.queryset.filter(page_title__icontains=lookup_content)
            elif "content_type" in lookup_title:
                qs = self.queryset.filter(content_type__icontains=lookup_content)
            elif "webserver" in lookup_title:
                qs = self.queryset.filter(webserver__icontains=lookup_content)
            elif "technology" in lookup_title:
                qs = self.queryset.filter(technologies__name__icontains=lookup_content)
            elif "gf_pattern" in lookup_title:
                qs = self.queryset.filter(matched_gf_patterns__icontains=lookup_content)
            elif "http_status" in lookup_title:
                try:
                    int_http_status = int(lookup_content)
                    qs = self.queryset.filter(http_status=int_http_status)
                except Exception as e:
                    print(e)
            elif "content_length" in lookup_title:
                try:
                    int_http_status = int(lookup_content)
                    qs = self.queryset.filter(content_length=int_http_status)
                except Exception as e:
                    print(e)
        elif ">" in search_value:
            search_param = search_value.split(">")
            lookup_title = search_param[0].lower().strip()
            lookup_content = search_param[1].lower().strip()
            if "http_status" in lookup_title:
                try:
                    int_val = int(lookup_content)
                    qs = self.queryset.filter(http_status__gt=int_val)
                except Exception as e:
                    print(e)
            elif "content_length" in lookup_title:
                try:
                    int_val = int(lookup_content)
                    qs = self.queryset.filter(content_length__gt=int_val)
                except Exception as e:
                    print(e)
        elif "<" in search_value:
            search_param = search_value.split("<")
            lookup_title = search_param[0].lower().strip()
            lookup_content = search_param[1].lower().strip()
            if "http_status" in lookup_title:
                try:
                    int_val = int(lookup_content)
                    qs = self.queryset.filter(http_status__lt=int_val)
                except Exception as e:
                    print(e)
            elif "content_length" in lookup_title:
                try:
                    int_val = int(lookup_content)
                    qs = self.queryset.filter(content_length__lt=int_val)
                except Exception as e:
                    print(e)
        elif "!" in search_value:
            search_param = search_value.split("!")
            lookup_title = search_param[0].lower().strip()
            lookup_content = search_param[1].lower().strip()
            if "http_url" in lookup_title:
                qs = self.queryset.exclude(http_url__icontains=lookup_content)
            elif "page_title" in lookup_title:
                qs = self.queryset.exclude(page_title__icontains=lookup_content)
            elif "content_type" in lookup_title:
                qs = self.queryset.exclude(content_type__icontains=lookup_content)
            elif "webserver" in lookup_title:
                qs = self.queryset.exclude(webserver__icontains=lookup_content)
            elif "technology" in lookup_title:
                qs = self.queryset.exclude(technologies__name__icontains=lookup_content)
            elif "gf_pattern" in lookup_title:
                qs = self.queryset.exclude(
                    matched_gf_patterns__icontains=lookup_content
                )
            elif "http_status" in lookup_title:
                try:
                    int_http_status = int(lookup_content)
                    qs = self.queryset.exclude(http_status=int_http_status)
                except Exception as e:
                    print(e)
            elif "content_length" in lookup_title:
                try:
                    int_http_status = int(lookup_content)
                    qs = self.queryset.exclude(content_length=int_http_status)
                except Exception as e:
                    print(e)
        return qs
